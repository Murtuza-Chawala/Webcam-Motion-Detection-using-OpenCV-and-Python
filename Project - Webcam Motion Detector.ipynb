{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture of the Webcam Motion Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intro:- \n",
    "    This is a real world motion detector program in python which captures frames through the webcam and checks if there is some \n",
    "    activity happening , it also prints a graph which shows for how much time there was activity(motion) in the frames captured by the webcam of our machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:-\n",
    "1) Capture the first frame,convert it into a grayscale and store it in a variable(*this frame will be compared with all the future frames)\n",
    "2) Capture the other frame,convert it into a grayscale and blur it using gaussian method for better accuracy.\n",
    "3) Find the difference_frame(ie delta_frame) between the default frame(first_frame) and the current frame(Using an inbuilt method)\n",
    "4) Display a new frame which shows the difference between two frames.\n",
    "5) The pixels(objects) which are different in both frames will have a grey-white color . \n",
    "6) Now find all pixels in the difference_frame which has pixel value of >100.(*in grayscale 255-white ; 0-black)\n",
    "7) Using these pixels create an outline drawing for all these pixels.\n",
    "8) Iterate through all the outlines(countors) and check if the outline object has pixel size of >500.\n",
    "9) If true: then draw a rectangle using the are of countors of objects having pixel size > 500.\n",
    "10) Draw the rectangle in the orginal frame(the color frame).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "first_frame=None\n",
    "video=cv2.VideoCapture(0)\n",
    "#A video is an array of frames(image).\n",
    "while True:\n",
    "    check, frame = video.read()\n",
    "    # gray -> The current frame\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    #Blurring the image to increase accuracy in calculation of difference.\n",
    "    gray =cv2.GaussianBlur(gray,(21,21),0) #Ignore the values these are used by default.\n",
    "    \n",
    "    #Store the first instance of the frame\n",
    "    if(first_frame is None):\n",
    "        first_frame = gray\n",
    "        continue #To go to next frame(as we do not want other line of code to be executed,will work only once)\n",
    "    \n",
    "    \n",
    "    #Difference between two frames(first and current)\n",
    "    delta_frame=cv2.absdiff(first_frame,gray) #Difference frame.\n",
    "    \n",
    "    \"\"\"\"\n",
    "    Assign a threshold:- . \n",
    "    #If the difference between each pixels of both frames is 30 then we will consider\n",
    "    #it as a white pixel and rest black pixel to get more accuracy(for contours)\n",
    "    \"\"\"\n",
    "    #Assign a threshold on delta_frame for pixels that have value = or > 30 assign value of 255(white color).\n",
    "    thresh_frame = cv2.threshold(delta_frame,30,255,cv2.THRESH_BINARY)[1] \n",
    "    \n",
    "    \n",
    "    \n",
    "    #Make the white pixels(objects) smoother and more accurate.\n",
    "    #Iterations means how many times to go through the image to remove (!needed) objects.\n",
    "    thresh_frame=cv2.dilate(thresh_frame,None, iterations =2) \n",
    "    \n",
    "    #Finding all contours of disctinct object in the thresh_frame.\n",
    "    #RETR_EXTERNAL :- Draw external contours on objects we will be finding.\n",
    "    (cnts,_) = cv2.findContours(thresh_frame.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "      \n",
    "    #Iterating through each contour and filtering(removing) the contour which has an area of < 1000px (!real world objects)\n",
    "    for contour in cnts:\n",
    "        if cv2.contourArea(contour) < 1000: #You can chage the value if you want to detect large objects. \n",
    "            continue #Ignore the contour having area less than 1000px.\n",
    "    \n",
    "        #If contour has size >1000 find the dimensions(x,y,w,h) of that contour\n",
    "        (x,y,w,h) = cv2.boundingRect(contour)\n",
    "        \n",
    "        #Draw a rectangle on the contour(of the original color frame) to identify the real world object.\n",
    "        cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 3)\n",
    "    \n",
    "  #  cv2.imshow(\"First Frame\",first_frame)\n",
    "  #  cv2.imshow(\"Current Frame\",gray)    \n",
    "  #  cv2.imshow(\"Difference Frame\",delta_frame)\n",
    "  #  cv2.imshow(\"Threshold Frame\",thresh_frame)\n",
    "    cv2.imshow(\"Color Frame\",frame) #Objects are identified in this frame.\n",
    "    \n",
    "    key = cv2.waitKey(1) #Wait for 1 milliseconds for user input \n",
    "    if(key==ord('q')):\n",
    "        break\n",
    "video.release() #Stop recording\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addition to Motion Detector Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captured Frames 0-No object detected ;  1-Object Detected\n",
      "[0, 0]\n",
      "\n",
      "Start and End times of objects in the frames\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import cv2,pandas\n",
    "from datetime import datetime\n",
    "\n",
    "first_frame=None\n",
    "status_list=[None,None] #Declare status list to find in how may frames object was present. \n",
    "times_list = [] #To catch the time when object came in and went out.\n",
    "df = pandas.DataFrame(columns=[\"Start\",\"End\"]) #Create a data structure.\n",
    "video=cv2.VideoCapture(0)\n",
    "#A video is an array of frames(image).\n",
    "while True:\n",
    "    check, frame = video.read()\n",
    "    status = 0 #0 - When no object is present in the frame and Vice versa\n",
    "    # gray -> The current frame\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    #Blurring the image to increase accuracy in calculation of difference.\n",
    "    gray =cv2.GaussianBlur(gray,(21,21),0) #Ignore the values these are used by default.\n",
    "    \n",
    "    #Store the first instance of the frame\n",
    "    if(first_frame is None):\n",
    "        first_frame = gray\n",
    "        continue #To go to next frame(as we do not want other line of code to be executed,will work only once)\n",
    "    \n",
    "    \n",
    "    #Difference between two frames(first and current)\n",
    "    delta_frame=cv2.absdiff(first_frame,gray) #Difference frame.\n",
    "    \n",
    "    \"\"\"\"\n",
    "    Assign a threshold:- . \n",
    "    #If the difference between each pixels of both frames is 30 then we will consider\n",
    "    #it as a white pixel and rest black pixel to get more accuracy(for contours)\n",
    "    \"\"\"\n",
    "    #Assign a threshold on delta_frame for pixels that have value = or > 30 assign value of 255(white color).\n",
    "    thresh_frame = cv2.threshold(delta_frame,30,255,cv2.THRESH_BINARY)[1] \n",
    "    \n",
    "    \n",
    "    \n",
    "    #Make the white pixels(objects) smoother and more accurate.\n",
    "    #Iterations means how many times to go through the image to remove (!needed) objects.\n",
    "    thresh_frame=cv2.dilate(thresh_frame,None, iterations =2) \n",
    "    \n",
    "    #Finding all contours of disctinct object in the thresh_frame.\n",
    "    #RETR_EXTERNAL :- Draw external contours on objects we will be finding.\n",
    "    (cnts,_) = cv2.findContours(thresh_frame.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "      \n",
    "    #Iterating through each contour and filtering(removing) the contour which has an area of < 1000px (!real world objects)\n",
    "    for contour in cnts:\n",
    "        if cv2.contourArea(contour) < 10000: #You can chage the value if you want to detect large objects. \n",
    "            continue #Ignore the contour having area less than 10000px.\n",
    "    \n",
    "        status = 1 #Some Object detected in the frame\n",
    "        #If contour has size >1000 find the dimensions(x,y,w,h) of that contour\n",
    "        (x,y,w,h) = cv2.boundingRect(contour)\n",
    "        \n",
    "        #Draw a rectangle on the contour(of the original color frame) to identify the real world object.\n",
    "        cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 3)\n",
    "        \n",
    "    #Appending status to the status_list which will show in how frames an object was detected.    \n",
    "    status_list.append(status)\n",
    "    \n",
    "    #For memory management, if we run webcam gor hours thousands of status will be recorded but we need only value of last two\n",
    "    status_list = status_list[-2:]\n",
    "    #If the object was [-1]==1 (not present) and [-2]==0 and (now is present)\n",
    "    if status_list[-1]==1 and status_list[-2]==0:\n",
    "        times_list.append(datetime.now())\n",
    "        \n",
    "    #If the object present and now is not present\n",
    "    if status_list[-1]==0 and status_list[-2]==1:\n",
    "        times_list.append(datetime.now())\n",
    "    \n",
    "    \n",
    "  #  cv2.imshow(\"First Frame\",first_frame)\n",
    "  #  cv2.imshow(\"Current Frame\",gray)    \n",
    "  #  cv2.imshow(\"Difference Frame\",delta_frame)\n",
    "  #  cv2.imshow(\"Threshold Frame\",thresh_frame)\n",
    "    cv2.imshow(\"Color Frame\",frame) #Objects are identified in this frame.\n",
    "    \n",
    "    key = cv2.waitKey(1) #Wait for 1 milliseconds for user input \n",
    "    if(key==ord('q')):\n",
    "        if status==1: #Object is detected \n",
    "            times_list.append(datetime.now()) #As there will not be an end time for the last detected object currently active. \n",
    "        break\n",
    "#Print a list which prints either 0 or 1 . 0-means no object detected , 1-means object was detected\n",
    "print(\"Captured Frames 0-No object detected ;  1-Object Detected\")\n",
    "print(status_list)\n",
    "print()\n",
    "print(\"Start and End times of objects in the frames\")\n",
    "print(times_list) #Will print the start and end values.\n",
    "\n",
    "\n",
    "\n",
    "#len() - returns length of the list ; range - iterate from which value to which value ; step - skip how many values here-(2)\n",
    "for i in range(0,len(times_list),2):\n",
    "    #Append Start time [i] and End time[i] to the panda dataframe in dictonary data sctructure.\n",
    "    #ignore_index=True useful because we are skipping the end time index and directly jumping from 0 to 2.\n",
    "    df = df.append({\"Start\":times_list[i],\"End\":times_list[i+1]},ignore_index=True)\n",
    "    \n",
    "df.to_csv(\"Times.csv\") #Exporting our data frame to a csv file.\n",
    "video.release() #Stop recording\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the timings in a quad graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bokeh'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2df8966f72a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbokeh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplotting\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbokeh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHoverTool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mColumnDataSource\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#df = pandas.read_csv(\"Times.csv\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'bokeh'"
     ]
    }
   ],
   "source": [
    "from bokeh.plotting import figure, show , output_file\n",
    "from bokeh.models import HoverTool,ColumnDataSource\n",
    "import pandas\n",
    "#df = pandas.read_csv(\"Times.csv\")\n",
    "\n",
    "#Converting data frame's start and end time to string in order to work with datetime type in HoverTool\n",
    "df[\"Start_string\"] = df[\"Start\"].dt.strftime(\"%Y-%M-%D %H:%M:%S\")\n",
    "df[\"End_string\"] = df[\"End\"].dt.strftime(\"%Y-%M-%D %H:%M:%S\")\n",
    "#Tell bokeh that we are using df as our column data source.\n",
    "cds = ColumnDataSource(df)\n",
    "\n",
    "#print(df[\"Start\"])\n",
    "p = figure(x_axis_type='datetime',height=300,width=1100,title=\"Motion Graph\")\n",
    "\n",
    "p.yaxis.minor_tick_line_color=None #To remove ticks in the y axis\n",
    "p.ygrid[0].ticker.desired_num_ticks=1 #To have only 1 grid in the y-axis\n",
    "\n",
    "#Create a hover object\n",
    "hover = HoverTool(tooltips=[(\"Start\",\"@Start_string\"),(\"End\",\"@End_string\")]) #@Start will fetch values from Data Frame's Start column.\n",
    "p.add_tools(hover)\n",
    "#Draw a quad(bar diagram) to plot start and end values.\n",
    "q=p.quad(left=\"Start\",right=\"End\",bottom=0,top=1,color=\"green\",source=cds)\n",
    "\n",
    "output_file(\"Graph.html\")\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shama Chawala\n"
     ]
    }
   ],
   "source": [
    "print(\"Shama Chawala\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
